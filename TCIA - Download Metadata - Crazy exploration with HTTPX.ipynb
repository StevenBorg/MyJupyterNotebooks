{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  This works with HTTPX\n",
    "async def foo():\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        url = 'https://services.cancerimagingarchive.net/services/v3/TCIA/query/getCollectionValues'\n",
    "        r = await client.get(url) #'https://www.example.com/')\n",
    "    return r\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    start = time.time()\n",
    "    await asyncio.gather(*[foo() for x in range(i)])\n",
    "    print(f'{i} runs in {time.time() - start} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call TCIA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import azure.storage.queue as asq\n",
    "import os\n",
    "import json\n",
    "\n",
    "# variables used throughout\n",
    "tciabase = 'https://services.cancerimagingarchive.net/services/v3/TCIA/query'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleRateLimits(headers):\n",
    "    limits = dict([(h,int(headers[h])) for h in headers if h.find('x-rate') != -1])\n",
    "    # Example : {'x-ratelimit-limit-hour': 360000, 'x-ratelimit-remaining-hour': 359961, 'x-ratelimit-limit-second': 1000, 'x-ratelimit-remaining-second': 999}\n",
    "    \n",
    "    # TODO: send a queue message to a queue which will 'pause' the querying from TCIA for the right time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def getCollectionsAsync():\n",
    "    urlGetCollections = f'{tciabase}/getCollectionValues'\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        r = await client.get(urlGetCollections)\n",
    "    \n",
    "    # not really needed here, but should send every time we send a request\n",
    "    handleRateLimits(r.headers)\n",
    "    \n",
    "    if r is not None:\n",
    "        #return [c['Collection'] for c in r.json()]\n",
    "        return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tcia_collections = await getCollectionsAsync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(tcia_collections)\n",
    "#print(tcia_collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://services.cancerimagingarchive.net/services/v3/TCIA/query/getPatientStudy?Collection=TCGA-GBM\n",
    "# https://services.cancerimagingarchive.net/services/v3/TCIA/query/getSeries?Collection=TCGA-GBM&StudyInstanceUID=1.3.6.1.4.1.14519.5.2.1.7695.4001.130563880911723253267280582465  \n",
    "# https://services.cancerimagingarchive.net/services/v3/TCIA/query/getImage?SeriesInstanceUID=1.3.6.1.4.1.14519.5.2.1.7695.4001.306204232344341694648035234440\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get PatientStudies in Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def getPatientStudiesPerCollection(collection):\n",
    "    urlGetPatientStudyBase = 'https://services.cancerimagingarchive.net/services/v3/TCIA/query/getPatientStudy'\n",
    "    params = {'Collection': collection}\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        r = await client.get(urlGetPatientStudyBase,params=params,timeout=None) #timeout=15.0)\n",
    "    \n",
    "    # not really needed here, but should send every time we send a request\n",
    "    handleRateLimits(r.headers)\n",
    "    \n",
    "    if r is not None:\n",
    "        #return [c['Collection'] for c in r.json()]\n",
    "        return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#studies = await getPatientStudiesPerCollection(collections[0]['Collection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(studies))\n",
    "#print(studies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#study_ids = [s['StudyInstanceUID'] for s in studies] # if s.find('StudyInstanceUID') != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def getSeriesPerStudy(study):\n",
    "    urlGetSeriesBase = 'https://services.cancerimagingarchive.net/services/v3/TCIA/query/getSeries'\n",
    "    params = {'StudyInstanceUID': study}\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        r = await client.get(urlGetSeriesBase,params=params,timeout=None) #timeout=15.0)\n",
    "    \n",
    "    # not really needed here, but should send every time we send a request\n",
    "    handleRateLimits(r.headers)\n",
    "    \n",
    "    if r is not None:\n",
    "        #return [c['Collection'] for c in r.json()]\n",
    "        return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#series = await getSeriesPerStudy(studies[0]['StudyInstanceUID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(series)\n",
    "#print(series[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the collections. We'll operate on one at a time\n",
    "tcia_collections = await getCollectionsAsync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already processed TCGA-GBM. Please check the data folder.\n",
      "studies in LIDC-IDRI : 1308\n"
     ]
    }
   ],
   "source": [
    "# For each collection, get the Studies, and then the Series\n",
    "# Hypothesis: pandas is far more memory efficient than Python dicts so first go get every single\n",
    "#   Study for all passed in collections and put into a DataFrame and THEN go get Series\n",
    "\n",
    "for collection in tcia_collections[:2]: # iter through the dictionaries in the list\n",
    "    \n",
    "    # To save a LOT of time, don't rerun collections if they've already been run\n",
    "    if os.path.exists(f'{collection[\"Collection\"]}-series.json'):\n",
    "        print(f'Already processed {collection[\"Collection\"]}. Please check the data folder.')\n",
    "        continue\n",
    "    \n",
    "    series_list = [] # list to store all the series for a collection\n",
    "    counter = 0\n",
    "    # Get the Studies\n",
    "    studies = await getPatientStudiesPerCollection(collection['Collection'])\n",
    "    print(f'studies in {collection[\"Collection\"]} : {len(studies)}')\n",
    "    #print(f'{collection[\"Collection\"]}_studies.csv')\n",
    "    study_df = pd.DataFrame.from_dict(studies)\n",
    "    study_df.to_csv(f'{collection[\"Collection\"]}_studies.csv')\n",
    "    \n",
    "    for study in studies[:3]:\n",
    "        series = await getSeriesPerStudy(study['StudyInstanceUID'])\n",
    "        counter += 1\n",
    "        if counter % 50 == 0:\n",
    "            print(str(counter))\n",
    "        \n",
    "        #create a list of series dicts (combining metadata from study)\n",
    "        for s in series:\n",
    "            # merge the dictionaries using ** to unpack the dictionaries (since .union is in place)\n",
    "            merged_dict = {**study, **s}\n",
    "            series_list.append(merged_dict)\n",
    "    \n",
    "    # Output results to a data folder to avoid having to burn time running again\n",
    "    study_df = pd.DataFrame.from_dict(series_list)\n",
    "    study_df.to_csv(f'data/{collection[\"Collection\"]}_studies_series.csv')\n",
    "   \n",
    "    # Also save just the resulting list, since that can be useful, too.  :-)\n",
    "    with open(f'data/{collection[\"Collection\"]}-series.json',\"w\") as f:\n",
    "        json.dump(series_list, f)\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "collection = tcia_collections[1]\n",
    "with open(f'data/{collection[\"Collection\"]}-series-test.json',\"w\") as f:\n",
    "    json.dump(series_list, f)\n",
    "    #series_list = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(series_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list if we need to\n",
    "collection = tcia_collections[1]\n",
    "with open(f'data/{collection[\"Collection\"]}-series-test.json',\"r\") as f:\n",
    "    l = json.load(f)\n",
    "type(l) # should read 'list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = asq.QueueClient.from_connection_string(conn_str='DefaultEndpointsProtocol=https;AccountName=sjbfunctest;AccountKey=XuYBliYrXazCmfDdK2jLcaJcfqPgu8tC43TlltTMY413nusjx2N6+IvErYmVXuZfOBVgVaCQ52RObKioS9FDRg==;EndpointSuffix=core.windows.net', queue_name='foofoo3')\n",
    "\n",
    "try:\n",
    "    p = q.get_queue_properties()\n",
    "except:\n",
    "    q.create_queue()\n",
    "q.send_message('Hello-There ')\n",
    "r = asq.TextBase64EncodePolicy()\n",
    "r.encode('TEST-THIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiofiles\n",
      "  Downloading aiofiles-0.5.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: aiofiles\n",
      "Successfully installed aiofiles-0.5.0\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 runs in 0.0 seconds\n",
      "1 runs in 0.6469912528991699 seconds\n",
      "2 runs in 0.6540677547454834 seconds\n",
      "3 runs in 0.7069270610809326 seconds\n",
      "4 runs in 1.1080455780029297 seconds\n",
      "5 runs in 1.0079903602600098 seconds\n",
      "6 runs in 1.2149596214294434 seconds\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Works with the addition of async with \n",
    "\n",
    "import httpx\n",
    "import asyncio\n",
    "import aiofiles\n",
    "\n",
    "async def download(url:str):\n",
    "    url = \"https://services.cancerimagingarchive.net/services/v3/TCIA/query/getCollections\"\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        resp = await client.get(url)\n",
    "    return resp\n",
    "\n",
    "async def download_lots(i):\n",
    "    url = \"https://services.cancerimagingarchive.net/services/v3/TCIA/query/getCollections\"\n",
    "    await asyncio.gather(*[download(url) for x in range(i)])\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    asyncio.run(download_lots))  # used outside of Jupyter when I don't have an event loop\n",
    "\n",
    "for i in range(7):\n",
    "    start = time.time()\n",
    "    await download_lots(i)\n",
    "    print(f'{i} runs in {time.time() - start} seconds')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 runs in 0.0 seconds\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object Response can't be used in 'await' expression",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-db9b2699cbdf>\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{i} runs in {time.time() - start} seconds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-138-db9b2699cbdf>\u001b[0m in \u001b[0;36mdownload_all_photos\u001b[1;34m(loops)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;31m#if __name__ == \"__main__\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m#    asyncio.run(download_all_photos('100_photos'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-138-db9b2699cbdf>\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(url, folder)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#async with aiofiles.open(os.path.join(folder, filename), \"wb\") as f:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;31m#    await f.write(resp.content)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object Response can't be used in 'await' expression"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "import asyncio\n",
    "import aiofiles\n",
    "\n",
    "import os\n",
    "\n",
    "async def download(url:str, folder:str):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    resp = await httpx.get(url)\n",
    "    resp.raise_for_status()\n",
    "    #async with aiofiles.open(os.path.join(folder, filename), \"wb\") as f:\n",
    "    #    await f.write(resp.content)\n",
    "\n",
    "\n",
    "async def download_all_photos(loops: str):\n",
    "    #resp = httpx.get(\"https://jsonplaceholder.typicode.com/photos\")\n",
    "    #resp.raise_for_status()\n",
    "    #urls = list(set(d[\"url\"] for d in resp.json()))[:10]\n",
    "    #os.makedirs(out_dir, exist_ok=True)\n",
    "    url = \"https://services.cancerimagingarchive.net/services/v3/TCIA/query/getCollectionValues\"\n",
    "    await asyncio.gather(*[download(url, \"bob\") for x in range(loops)])\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    asyncio.run(download_all_photos('100_photos'))\n",
    "\n",
    "for i in range(5):\n",
    "    start = time.time()\n",
    "    await download_all_photos(i)\n",
    "    print(f'{i} runs in {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200 OK]>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async with httpx.AsyncClient() as client:\n",
    "    r = await client.get('https://www.example.com/')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  This works with HTTPX\n",
    "async def foo():\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        url = 'https://services.cancerimagingarchive.net/services/v3/TCIA/query/getCollectionValues'\n",
    "        r = await client.get(url) #'https://www.example.com/')\n",
    "    return r\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    start = time.time()\n",
    "    await asyncio.gather(*[foo() for x in range(i)])\n",
    "    print(f'{i} runs in {time.time() - start} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 runs in 0.0 seconds\n",
      "1 runs in 0.655052900314331 seconds\n",
      "2 runs in 0.706932544708252 seconds\n",
      "3 runs in 0.7170536518096924 seconds\n",
      "4 runs in 1.0249478816986084 seconds\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "from aiohttp import ClientSession\n",
    "import asyncio\n",
    "\n",
    "async def call_url(x, session):\n",
    "    url = \"https://services.cancerimagingarchive.net/services/v3/TCIA/query/getSeries?Collection=TCGA-GBM&StudyInstanceUID=1.3.6.1.4.1.14519.5.2.1.7695.4001.130563880911723253267280582465\"\n",
    "    \n",
    "    response = await session.get(url, timeout=None)\n",
    "    response_json = await response.json()\n",
    "    return response_json\n",
    "\n",
    "\n",
    "async def run_program(x, session):\n",
    "    \"\"\"Wrapper for running program in an asynchronous manner\"\"\"\n",
    "    #try:\n",
    "    response = await call_url(x, session)\n",
    "        #print(f\"Response: {json.dumps(response, indent=2)}\")\n",
    "    #except Exception as err:\n",
    "        #print(f\"Exception occured: {err}\")\n",
    "        #pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "__aexit__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-bc9f5522ee0c>\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrun_program\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m    \u001b[1;31m# print(f'{i} runs in {time.time() - start}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: __aexit__"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(5):\n",
    "    start = time.time()\n",
    "    #async with httpx.AsyncClient() as session:\n",
    "    async with ClientSession as sesssion:\n",
    "        await asyncio.gather(*[run_program(x,session) for x in range(i)])\n",
    "   # print(f'{i} runs in {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    try:\n",
    "        response = await session.request(method='GET', url=url)\n",
    "        response.raise_for_status()\n",
    "        print(f\"Response status ({url}): {response.status}\")\n",
    "    except HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err}\")\n",
    "    except Exception as err:\n",
    "        print(f\"An error ocurred: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 call(s) in 0.6880629062652588 seconds\n",
      "2 call(s) in 0.6539404392242432 seconds\n",
      "3 call(s) in 0.6569993495941162 seconds\n",
      "4 call(s) in 0.8340511322021484 seconds\n"
     ]
    }
   ],
   "source": [
    "# Works with aiohttp but not httpx \n",
    "import aiohttp\n",
    "import asyncio\n",
    "import time\n",
    "import httpx\n",
    "\n",
    "async def call_url(session):\n",
    "    url = \"https://services.cancerimagingarchive.net/services/v3/TCIA/query/getCollections\"\n",
    "    #response = await session.request(method='GET', url=url)\n",
    "    response = await session.get(url=url)\n",
    "\n",
    "    return response\n",
    "\n",
    "for i in range(1,5):\n",
    "    start = time.time() # start time for timing event\n",
    "    async with aiohttp.ClientSession() as session: #use aiohttp\n",
    "    #async with httpx.AsyncClient as session:  #use httpx\n",
    "        await asyncio.gather(*[call_url(session) for x in range(i)])\n",
    "    print(f'{i} call(s) in {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 call(s) in 0.6497354507446289 seconds\n",
      "2 call(s) in 0.6889312267303467 seconds\n",
      "3 call(s) in 0.6750121116638184 seconds\n",
      "4 call(s) in 0.8299829959869385 seconds\n"
     ]
    }
   ],
   "source": [
    "#Works with HTTPX\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import time\n",
    "import httpx\n",
    "\n",
    "async def call_url(session = None):\n",
    "    url = \"https://services.cancerimagingarchive.net/services/v3/TCIA/query/getCollectionValues\"\n",
    "    response = await session.get(url=url)\n",
    "    return response\n",
    "\n",
    "for i in range(1,5):\n",
    "    start = time.time() # start time for timing event\n",
    "    #async with aiohttp.ClientSession() as session: #use aiohttp\n",
    "    session = httpx.AsyncClient() #use httpx\n",
    "    await asyncio.gather(*[call_url(session) for x in range(i)])\n",
    "    await session.aclose()\n",
    "    print(f'{i} call(s) in {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 call(s) in 0.0 seconds\n",
      "1 call(s) in 7.978963136672974 seconds\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    start = time.time()\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "    #async with httpx.AsyncClient as session:\n",
    "        await asyncio.gather(*[call_url(session) for x in range(i)])\n",
    "    print(f'{i} call(s) in {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "__aexit__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-544c8e71e80a>\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{i} call(s) in {time.time() - start} seconds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-544c8e71e80a>\u001b[0m in \u001b[0;36mcall_url\u001b[1;34m(session)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: __aexit__"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import time\n",
    "import httpx\n",
    "\n",
    "async def call_url(session):\n",
    "    url = \"https://services.cancerimagingarchive.net/services/v3/TCIA/query/getCollections\"\n",
    "    #async with aiohttp.ClientSession() as session: #use aiohttp\n",
    "    async with httpx.AsyncClient as session:  #use httpx\n",
    "        response = await session.get(url=url)\n",
    "\n",
    "    return response\n",
    "\n",
    "for i in range(1,5):\n",
    "    start = time.time() # start time for timing event\n",
    "    await asyncio.gather(*[call_url(session) for x in range(i)])\n",
    "    print(f'{i} call(s) in {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(series_list))\n",
    "print(series_list[:1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df = pd.DataFrame.from_dict(series_list)\n",
    "study_df.to_csv(f'data/{tcia_collections[0][\"Collection\"]}_studies_series.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(study_df)\n",
    "with open('data/TCGA-GBM-series.json',\"w\") as f:\n",
    "    f.write(str(series_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_sample = series[0]    \n",
    "study_sample = studies[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "series_fields = [x for x in series_sample]\n",
    "study_fields = [x for x in study_sample]\n",
    "print(len(series_fields))\n",
    "print(len(study_fields))\n",
    "merged = list(set(series_fields).union(set(study_fields)))\n",
    "\n",
    "merged2 = {**study_sample, **series_sample}\n",
    "\n",
    "print(study_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_sample.update(series_sample)\n",
    "print(len(study_sample))\n",
    "print(study_sample)\n",
    "\n",
    "merged2 = {**study_sample, **series_sample}\n",
    "print(len(merged2))\n",
    "print(merged2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_sample.update(series_sample)\n",
    "print(len(study_sample))\n",
    "study_sample\n",
    "from collections import OrderedDict\n",
    "od = OrderedDict(study_sample)\n",
    "od\n",
    "\n",
    "x = []\n",
    "x.append(study_sample)\n",
    "\n",
    "df = pd.DataFrame.from_dict(x)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(series_sample)\n",
    "print(study_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://services.cancerimagingarchive.net/services/v3/TCIA/query/getSeries?Collection=TCGA-GBM&StudyInstanceUID=1.3.6.1.4.1.14519.5.2.1.7695.4001.130563880911723253267280582465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = [s['StudyInstanceUID'] for s in res.json()]\n",
    "#for x in res.json():\n",
    "#    print(x['StudyInstanceUID'])\n",
    "studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for x in collections.json()[:2]:\n",
    "        print(x['Collection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with all the studies\n",
    "studies = [s['StudyInstanceUID'] for s in res.json()]\n",
    "\n",
    "\n",
    "#storageConnString = os.environ[\"AzureWebJobsStorage\"]\n",
    "storageConnString = 'DefaultEndpointsProtocol=https;AccountName=sjbfunctest;AccountKey=XuYBliYrXazCmfDdK2jLcaJcfqPgu8tC43TlltTMY413nusjx2N6+IvErYmVXuZfOBVgVaCQ52RObKioS9FDRg==;EndpointSuffix=core.windows.net'\n",
    "\n",
    "#x = asq.QueueService(account_name='sjbfunctest', account_key='mykey')\n",
    "#service = asq.QueueServiceClient.from_connection_string(conn_str=connection_string)\n",
    "patient_studies_queue = asq.QueueClient.from_connection_string(conn_str=storageConnString,queue_name='studies')\n",
    "\n",
    "# Create the queue if it doesn't exist...  by exception\n",
    "#   Which is hacky, but effective\n",
    "try:\n",
    "    patient_studies_queue.get_queue_properties()\n",
    "except:\n",
    "    patient_studies_queue.create_queue()\n",
    "\n",
    "# Must base-64 encode since... functions...\n",
    "enc = asq.TextBase64EncodePolicy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for study in studies:\n",
    "    b64 = enc.encode(study)\n",
    "    patient_studies_queue.send_message(b64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(studies)\n",
    "study_id = studies[0]\n",
    "study_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_id = studies[0]\n",
    "\n",
    "urlGetSeries = 'https://services.cancerimagingarchive.net/services/v3/TCIA/query/getSeries'\n",
    "params = {'StudyInstanceUID': study_id}\n",
    "res = requests.get(urlGetSeries,params=params,timeout=None) #timeout=15.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.json()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with all the studies\n",
    "series = [s['SeriesInstanceUID'] for s in res.json()]\n",
    "\n",
    "series\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storageConnString = os.environ[\"AzureWebJobsStorage\"]\n",
    "storageConnString = 'DefaultEndpointsProtocol=https;AccountName=sjbfunctest;AccountKey=XuYBliYrXazCmfDdK2jLcaJcfqPgu8tC43TlltTMY413nusjx2N6+IvErYmVXuZfOBVgVaCQ52RObKioS9FDRg==;EndpointSuffix=core.windows.net'\n",
    "\n",
    "series_queue = asq.QueueClient.from_connection_string(conn_str=storageConnString,queue_name='series')\n",
    "\n",
    "# Create the queue if it doesn't exist...  by exception\n",
    "#   Which is hacky, but effective\n",
    "try:\n",
    "    series_queue.get_queue_properties()\n",
    "except:\n",
    "    series_queue.create_queue()\n",
    "\n",
    "# Must base-64 encode since... functions...\n",
    "enc = asq.TextBase64EncodePolicy()\n",
    "\n",
    "for s in series[:1]:\n",
    "    b64 = enc.encode(s)\n",
    "    series_queue.send_message(b64)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the zip files\n",
    "url = 'https://services.cancerimagingarchive.net/services/v3/TCIA/query/getImage?SeriesInstanceUID=1.3.6.1.4.1.14519.5.2.1.7695.4001.306204232344341694648035234440'\n",
    "res = requests.get(url,timeout=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Get the study id from the base-64 encoded incoming queue\n",
    "#series_id = msg.get_body().decode('utf-8')\n",
    "series_id = series[0]\n",
    "\n",
    "series_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlGetImage = 'https://services.cancerimagingarchive.net/services/v3/TCIA/query/getImage'\n",
    "params = {'SeriesInstanceUID': series_id}\n",
    "res = requests.get(urlGetImage,params=params,timeout=None) #timeout=15.0)\n",
    "print(res.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "\n",
    "def download_file(url):\n",
    "    local_filename = \"foo4.zip\"\n",
    "    with requests.get(urlGetImage, stream=True) as r:\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    return local_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_filename = \"food4.zip\"\n",
    "with requests.get(urlGetImage,params=params,timeout=None, stream=True) as r:\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        shutil.copyfileobj(r.raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "file_like_object = io.BytesIO(res.content)\n",
    "z = zipfile.ZipFile(file_like_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = z.filelist\n",
    "f1 = files[1]\n",
    "\n",
    "#for f in files:\n",
    "    #print(f)\n",
    "    #z.read(f)\n",
    "dcmbytes = z.read(f)\n",
    "#dcmbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install azure.storage.blob\n",
    "\n",
    "import azure.storage.blob as blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = f1.filename.split('/')\n",
    "dcm_names = [p for p in parts if p.find('.dcm') != -1]\n",
    "if len(dcm_names) > 0:\n",
    "    dcm_name = dcm_names[0]\n",
    "dcm_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storageConnString = 'DefaultEndpointsProtocol=https;AccountName=sjbfunctest;AccountKey=XuYBliYrXazCmfDdK2jLcaJcfqPgu8tC43TlltTMY413nusjx2N6+IvErYmVXuZfOBVgVaCQ52RObKioS9FDRg==;EndpointSuffix=core.windows.net'\n",
    "\n",
    "b = blob.ContainerClient.from_connection_string(conn_str=storageConnString,container_name='dicoms2')\n",
    "\n",
    "# Create the queue if it doesn't exist...  by exception\n",
    "#   Which is hacky, but effective\n",
    "try:\n",
    "    b.get_container_properties()\n",
    "except:\n",
    "    b.create_container()\n",
    "\n",
    "for f in files:\n",
    "    dicom_file = z.read(f)\n",
    "    parts = f.filename.split('/')\n",
    "    dcm_parts = [p for p in parts if p.find('.dcm') != -1]\n",
    "    if len(dcm_parts) == 1: # we have a dicom file, and only one\n",
    "        dcm_name = f'{series_id}/{dcm_parts[0]}'\n",
    "        print(dcm_name)\n",
    "        up = b.upload_blob(data=z.read(f), name=dcm_name)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#upblob = b.upload_blob(data=dcmbytes,name='test3.dcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upblob.blob_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "storageConnString = 'DefaultEndpointsProtocol=https;AccountName=sjbfunctest;AccountKey=XuYBliYrXazCmfDdK2jLcaJcfqPgu8tC43TlltTMY413nusjx2N6+IvErYmVXuZfOBVgVaCQ52RObKioS9FDRg==;EndpointSuffix=core.windows.net'\n",
    "\n",
    "series_queue = asq.QueueClient.from_connection_string(conn_str=storageConnString,queue_name='series')\n",
    "\n",
    "# Create the queue if it doesn't exist...  by exception\n",
    "#   Which is hacky, but effective\n",
    "try:\n",
    "    series_queue.get_queue_properties()\n",
    "except:\n",
    "    series_queue.create_queue()\n",
    "\n",
    "# Must base-64 encode since... functions...\n",
    "enc = asq.TextBase64EncodePolicy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create a list with all the studies\n",
    "    series = [s['SeriesInstanceUID'] for s in res.json()]\n",
    "\n",
    "\n",
    "    storageConnString = os.environ[\"AzureWebJobsStorage\"]\n",
    "  \n",
    "    series_queue = asq.QueueClient.from_connection_string(conn_str=storageConnString,queue_name='series')\n",
    "\n",
    "    # Create the queue if it doesn't exist...  by exception\n",
    "    #   Which is hacky, but effective\n",
    "    try:\n",
    "        series_queue.get_queue_properties()\n",
    "    except:\n",
    "        series_queue.create_queue()\n",
    "\n",
    "    # Must base-64 encode since... functions...\n",
    "    enc = asq.TextBase64EncodePolicy()\n",
    "\n",
    "    for s in series:\n",
    "        b64 = enc.encode(s)\n",
    "        series_queue.send_message(b64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import asyncio\n",
    "import aiofiles\n",
    "\n",
    "import os\n",
    "\n",
    "async def download(url:str, folder:str):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    resp = await httpx.get(url)\n",
    "    resp.raise_for_status()\n",
    "    async with aiofiles.open(os.path.join(folder, filename), \"wb\") as f:\n",
    "        await f.write(resp.content)\n",
    "\n",
    "\n",
    "async def download_all_photos(out_dir: str):\n",
    "    resp = await httpx.get(\"https://jsonplaceholder.typicode.com/photos\")\n",
    "    resp.raise_for_status()\n",
    "    urls = list(set(d[\"url\"] for d in resp.json()))[:100]\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    await asyncio.gather(*[download(url, out_dir) for url in urls])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(download_all_photos('100_photos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WORKS\n",
    "\n",
    "import httpx\n",
    "import asyncio\n",
    "import aiofiles\n",
    "\n",
    "import os\n",
    "\n",
    "async def download(url:str, folder:str):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    async with httpx.AsyncClient() as session:\n",
    "        resp = await session.get(url)\n",
    "        resp.raise_for_status()\n",
    "    async with aiofiles.open(os.path.join(folder, filename), \"wb\") as f:\n",
    "        await f.write(resp.content)\n",
    "        \n",
    "async def download_all_photos(out_dir: str):\n",
    "    async with httpx.AsyncClient() as session:\n",
    "        resp = await session.get(\"https://jsonplaceholder.typicode.com/photos\")\n",
    "        resp.raise_for_status()\n",
    "    urls = list(set(d[\"url\"] for d in resp.json()))[:100]\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    await asyncio.gather(*[download(url, out_dir) for url in urls])\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    asyncio.run(download_all_photos('100_photos'))\n",
    "    \n",
    "await download_all_photos('100_photos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_stuff(f):\n",
    "    f.write('And stuff with context passed to another method. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_stuff(f):\n",
    "    f.write('And stuff with context passed to another method. ')\n",
    "    \n",
    "with open('foo.txt',\"w\") as f:\n",
    "    f.write('Start with context manager inside with statement. ')\n",
    "    write_stuff(f)\n",
    "    f.write('And back to close the with.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: httpx\n",
      "Version: 0.12.1\n",
      "Summary: The next generation HTTP client.\n",
      "Home-page: https://github.com/encode/httpx\n",
      "Author: Tom Christie\n",
      "Author-email: tom@tomchristie.com\n",
      "License: BSD\n",
      "Location: c:\\users\\stborg\\appdata\\local\\continuum\\anaconda3\\envs\\fastai2\\lib\\site-packages\n",
      "Requires: idna, chardet, certifi, h2, sniffio, urllib3, h11, hstspreload, rfc3986\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show httpx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
